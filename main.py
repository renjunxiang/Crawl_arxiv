import os, json
from tools.find_paper import find_arxiv_papers
from tools.filter_paper import FilterPaper
from tools.download_paper import DownloadPaper
from tools.filter_institution import find_institution_batch
from tools.write_note import write_notes
from tools.prepare_materials import write_copy, pdf_first_page_to_image
import argparse

parser = argparse.ArgumentParser(description="Process some integers.")
parser.add_argument("-d", "--date", type=str, help='æ—¥æœŸï¼Œæ ¼å¼ä¸º"YYYY-MM-DD"')
args = parser.parse_args()

if not os.path.exists("./output"):
    os.makedirs("./output")


async def main(date: str, filter_llm: str, institution_llm: str, note_llm: str):
    """
    ä¸»å‡½æ•°ï¼Œæ ¹æ®æ—¥æœŸç­›é€‰å¤§æ¨¡å‹ç›¸å…³è®ºæ–‡å¹¶ç”Ÿæˆç¬”è®°

    Args:
        date (str): æ—¥æœŸï¼Œæ ¼å¼ä¸º"YYYY-MM-DD"
        filter_llm (str):ç­›é€‰æ˜¯å¦å¤§æ¨¡å‹ç›¸å…³ï¼Œè°ƒç”¨çš„å¤§æ¨¡å‹åç§°
        institution_llm (str): ç­›é€‰æ˜¯å¦æŒ‡å®šæœºæ„ï¼Œè°ƒç”¨çš„å¤§æ¨¡å‹åç§°
        note_llm (str): å†™ç¬”è®°çš„å¤§æ¨¡å‹åç§°
    """
    # åˆ›å»ºæ—¥æœŸç›®å½•
    if not os.path.exists(f"./output/{date}"):
        os.makedirs(f"./output/{date}")

    # =================================è·å–æŒ‡å®šæ—¥æœŸè®ºæ–‡=================================
    if os.path.exists(f"./output/{date}/papers.json"):
        with open(f"./output/{date}/papers.json", "r", encoding="utf-8") as f:
            papers = json.load(f)
    else:
        categories = ["cs.CL", "cs.AI", "cs.LG", "cs.IR", "cs.CV"]
        papers = find_arxiv_papers(
            categories, start_time=date, end_time=date, max_results=1000
        )
        print(f"æŸ¥è¯¢åˆ° {len(papers)} ç¯‡è®ºæ–‡\n")
        # æŒ‡å®šæ—¥æœŸçš„è®ºæ–‡æ¸…å•
        with open(f"./output/{date}/papers.json", "w", encoding="utf-8") as f:
            json.dump(papers, f, ensure_ascii=False, indent=4)

    # =================================ç­›é€‰å¤§æ¨¡å‹è®ºæ–‡=================================
    print(f"å¼€å§‹ç­›é€‰å¤§æ¨¡å‹ç›¸å…³è®ºæ–‡")
    if os.path.exists(f"./output/{date}/papers_filter.json"):
        with open(f"./output/{date}/papers_filter.json", "r", encoding="utf-8") as f:
            papers_filter = json.load(f)
    else:
        filter = FilterPaper(model_name=filter_llm, max_concurrent=5)
        results = await filter.process_batch_llm(papers[:])
        papers_filter = []
        for res in results:
            if res["tag"] != "ä¸ç›¸å…³":
                papers_filter.append(res)
        print(f"ç­›é€‰å‡º {len(papers_filter)} ç¯‡è®ºæ–‡\n")
        # æ»¡è¶³æ¡ä»¶çš„è®ºæ–‡æ¸…å•
        with open(f"./output/{date}/papers_filter.json", "w", encoding="utf-8") as f:
            json.dump(papers_filter, f, ensure_ascii=False, indent=4)

    # =================================ä¸‹è½½è®ºæ–‡=================================
    print(f"å¼€å§‹ä¸‹è½½è®ºæ–‡")
    if os.path.exists(f"./output/{date}/downloaded.json"):
        with open(f"./output/{date}/downloaded.json", "r", encoding="utf-8") as f:
            download_info = json.load(f)
    else:
        dp = DownloadPaper(target_folder=f"./output/{date}/papers")
        download_info = dp.download_papers(papers_filter[:])
        print(f"ä¸‹è½½å®Œæˆ {len(download_info)} ç¯‡è®ºæ–‡\n")
        with open(
            os.path.join(f"./output/{date}", "downloaded.json"),
            "w",
            encoding="utf-8",
        ) as f:
            json.dump(download_info, f, ensure_ascii=False, indent=4)

    # =================================æœºæ„ç­›é€‰=================================
    """
    1.è¯»å–downloaded.jsonæ–‡ä»¶
    2.éå†æ¯ä¸€ç¯‡è®ºæ–‡ï¼Œæ ¹æ®æ˜¯å¦æœ‰institution_statuså­—æ®µè¯†åˆ«æ˜¯å¦å·²ç»ç»è¿‡æœºæ„ç­›é€‰
    3.å¦‚æœæ²¡æœ‰institution_statuså­—æ®µï¼Œåˆ™å°†å…¶è®¾ç½®ä¸ºpendingï¼Œç­‰å¾…åç»­å¤„ç†ã€‚
    4.å…¨éƒ¨å¤„ç†å®Œåï¼Œæ ¹æ®institution_statuså­—æ®µç­›é€‰å‡ºkeepçš„è®ºæ–‡ã€‚
    5.å°†ç­›é€‰å‡ºçš„è®ºæ–‡ä¿å­˜åˆ°filter_institution.jsonæ–‡ä»¶ä¸­ã€‚
    """
    print(f"å¼€å§‹æ ¹æ®æœºæ„ç­›é€‰è®ºæ–‡")
    if os.path.exists(f"./output/{date}/filter_institution.json"):
        with open(
            f"./output/{date}/filter_institution.json", "r", encoding="utf-8"
        ) as f:
            filter_institution = json.load(f)
    else:
        downloaded_json_path = f"./output/{date}/downloaded.json"

        # åˆå§‹åŒ– institution_status å­—æ®µï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        for paper in download_info:
            if "institution_status" not in paper:
                paper["institution_status"] = "pending"

        # ä¿å­˜åˆå§‹åŒ–åçš„çŠ¶æ€
        with open(downloaded_json_path, "w", encoding="utf-8") as f:
            json.dump(download_info, f, ensure_ascii=False, indent=4)

        # è¿‡æ»¤å‡ºå¾…å¤„ç†çš„è®ºæ–‡
        pending_papers = [
            p for p in download_info if p.get("institution_status") == "pending"
        ]

        if pending_papers:
            print(f"å¾…å¤„ç†è®ºæ–‡: {len(pending_papers)} ç¯‡")
            await find_institution_batch(
                pending_papers,
                institution_llm,
                downloaded_json_path=downloaded_json_path,
                max_concurrent=5,
            )
            # é‡æ–°åŠ è½½æ›´æ–°åçš„ download_info
            with open(downloaded_json_path, "r", encoding="utf-8") as f:
                download_info = json.load(f)
        else:
            print(f"æ‰€æœ‰è®ºæ–‡å·²å¤„ç†å®Œæˆ")

        # æå–å·²å¤„ç†çš„è®ºæ–‡ä½œä¸º filter_institution
        filter_institution = [
            p for p in download_info if p.get("institution_status") == "keep"
        ]
        print(f"æ ¹æ®æœºæ„ç­›é€‰å‡º {len(filter_institution)} ç¯‡è®ºæ–‡\n")

        # ä¿å­˜ filter_institution.jsonï¼ˆç”¨äºåç»­æ­¥éª¤ï¼‰
        with open(
            f"./output/{date}/filter_institution.json", "w", encoding="utf-8"
        ) as f:
            json.dump(filter_institution, f, ensure_ascii=False, indent=4)

    # =================================å†™ç¬”è®°=================================
    if os.path.exists(f"./output/{date}/notes.json"):
        with open(f"./output/{date}/notes.json", "r", encoding="utf-8") as f:
            notes = json.load(f)
    else:
        notes = await write_notes(filter_institution, note_llm, max_concurrent=5)
        print(f"å†™å¥½ {len(notes)} ç¯‡è®ºæ–‡çš„ç¬”è®°")
        # æ»¡è¶³æ¡ä»¶çš„è®ºæ–‡ç¬”è®°ï¼ŒæŒ‰ç…§titleæ’åº
        notes.sort(key=lambda x: x["title"])
        with open(f"./output/{date}/notes.json", "w", encoding="utf-8") as f:
            json.dump(notes, f, ensure_ascii=False, indent=4)

    if not os.path.exists(f"./output/{date}/notes.txt"):
        with open(f"./output/{date}/notes.txt", "w", encoding="utf-8") as f:
            for note in notes:
                f.write("=" * 30 + "\n\n")
                f.write(note["institution"] + "\n\n")
                f.write(note["note"] + "\n\n")

    # =================================ç¬”è®°åˆ†ç±»=================================
    if not os.path.exists(f"./output/{date}/institution"):
        os.makedirs(f"./output/{date}/institution")

    industry, foreign_academia, domestic_academia, other = (
        [],
        [],
        [],
        [],
    )
    for note in notes:
        if note["institution_category"] == "å›½å¤–å·¥ä¸šç•Œ":
            industry.append(note)
        elif note["institution_category"] == "å›½å†…å·¥ä¸šç•Œ":
            industry.append(note)
        elif note["institution_category"] == "å›½å¤–å­¦æœ¯ç•Œ":
            foreign_academia.append(note)
        elif note["institution_category"] == "å›½å†…å­¦æœ¯ç•Œ":
            domestic_academia.append(note)
        else:
            other.append(note)

    for file_name, notes in [
        ("industry", industry),
        ("foreign_academia", foreign_academia),
        ("domestic_academia", domestic_academia),
        ("other", other),
    ]:
        if not os.path.exists(f"./output/{date}/institution/{file_name}"):
            os.makedirs(f"./output/{date}/institution/{file_name}")
        # ä¿å­˜ JSON æ–‡ä»¶
        with open(
            f"./output/{date}/institution/{file_name}/{file_name}.json",
            "w",
            encoding="utf-8",
        ) as f:
            json.dump(notes, f, ensure_ascii=False, indent=4)
            print(f"åˆè®¡ {len(notes)} ç¯‡{file_name}çš„è®ºæ–‡ç¬”è®°")
        # ä¿å­˜ç¬”è®°txtæ–‡ä»¶
        with open(
            f"./output/{date}/institution/{file_name}/{file_name}.txt",
            "w",
            encoding="utf-8",
        ) as f:
            for note in notes:
                f.write("=" * 30 + "\n\n")
                f.write(note["institution"] + "\n\n")
                f.write(note["note"] + "\n\n")

    # =================================ç”Ÿæˆç´ æ=================================
    image_id = 0
    for file_name, notes in [
        ("industry", industry),
        ("foreign_academia", foreign_academia),
        ("domestic_academia", domestic_academia),
        ("other", other),
    ]:
        # æŒ‰ç…§æœºæ„å½’ç±»è®ºæ–‡ç®€ä»‹
        contents = {}
        for note in notes:
            first_institution = note["first_institution"]
            pdf_path = note["file_path"]
            arxiv_id = note["arxiv_id"]
            content = write_copy(note)
            if first_institution not in contents:
                contents[first_institution] = []
            contents[first_institution].append([content, pdf_path, arxiv_id])

        # ç”Ÿæˆè®ºæ–‡é¦–é¡µå›¾ç‰‡å¹¶æŒ‰ç…§ç®€ä»‹é¡ºåºæ’åºï¼Œæ–¹ä¾¿åç»­ç›´æ¥ä¸Šä¼ ç¬”è®°
        with open(
            f"./output/{date}/institution/{file_name}/content.txt",
            "w",
            encoding="utf-8",
        ) as f:
            for institution, contents in contents.items():
                f.write(f"\nğŸ›ï¸{institution}\n")
                for [content, pdf_path, arxiv_id] in contents:
                    f.write(content + "\n")
                    pdf_first_page_to_image(
                        pdf_path=pdf_path,
                        output_img_path=f"./output/{date}/institution/{file_name}/{image_id}_{arxiv_id}.png",
                        dpi=300,
                        img_format="png",
                    )
                    image_id += 1


if __name__ == "__main__":
    import asyncio

    model_name = {
        "filter": "qwen3.5-plus",
        "institution": "qwen3.5-plus",
        "note": "qwen-plus",
    }

    asyncio.run(
        main(
            args.date,
            model_name["filter"],
            model_name["institution"],
            model_name["note"],
        )
    )
