
🛎️Anthropic
🔸2602.22755v1：提出了首个大规模、多样化、带可控隐藏行为的语言模型基准AuditBench，并基于其首次实证揭示了“工具到代理”效能断层等关键规律。

🛎️微软
🔸2602.23008v1：提出EMPO2框架，通过记忆增强与混合（on-和off-policy）优化协同提升LLM智能体的探索能力与泛化性，在无需参数更新下即可快速适应新任务。
🔸2602.22719v1：首次提出“激活子空间瓶颈”概念，系统识别Mamba中由dt_proj.bias主导的层级信息压缩瓶颈，并通过轻量级激活缩放干预和架构改进Stable-Mamba，显著提升多任务性能且无需任务微调。

🛎️美团
🔸2602.22697v1：提出InteractCS-RL框架，首次将任务型对话建模为兼顾会话过程质量、终端结果效用与全局成本约束的多粒度强化学习问题，并实现帕累托最优平衡。

🛎️字节跳动
🔸2602.22575v1：提出S2O方法，通过轻量级在线置换与重要性驱动的早停机制，在不物理重排张量的前提下显著提升有效稀疏度，同时控制误差预算。

🛎️腾讯
🔸2602.22576v1：提出SEARCH-P1框架，通过路径中心奖励塑形，从推理轨迹结构质量中提取密集、细粒度、容错的学习信号，显著提升训练稳定性与效率。
🔸2602.22584v1：提出首个面向工业广告QA的检索-生成联合强化协同框架，通过图感知检索与多维奖励约束的RL联合优化，显著抑制幻觉并提升线上用户满意度。

🛎️英伟达
🔸2602.22603v1：提出SideQuest框架，首次将KV缓存管理建模为大推理模型（LRM）自主执行的并行辅助任务，通过模型自身语义理解动态识别并清除失效工具响应，显著降低内存开销且几乎不损推理精度。

🛎️华为
🔸2602.22871v1：提出一种训练无关、模块化的“扩散思维拼接”框架，通过步骤级奖励引导筛选与重组，显著提升数学与代码任务的准确率-延迟帕累托前沿。

🛎️谷歌
🔸2602.22647v1：提出STATIC框架，将前缀树（Trie）约束转化为静态稀疏矩阵运算，首次实现工业级严格约束生成式检索的零显著延迟部署。
