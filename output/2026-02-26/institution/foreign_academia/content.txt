
🛎️新加坡国立大学
🔸2602.22700v1：提出IMMACULATE框架，首次将概率化抽样审计与可验证计算结合，并设计Logit距离分布（LDD）作为抗浮点非确定性的可验证度量，实现低开销、强保证、全兼容的黑箱LLM审计。
🔸2602.22583v1：提出“策略可执行性”新概念，揭示策略在人类解法中出现与在模型上成功引导之间的系统性脱节，并据此设计轻量级测试时框架SSR。

🛎️卡内基梅隆大学
🔸2602.23320v1：提出ParamMem——一种将跨样本反思模式编码进模型参数的轻量级参数化记忆模块，通过温度控制采样生成多样化反思信号，显著提升语言代理的推理能力。

🛎️华盛顿大学
🔸2602.23351v1：首次系统揭示并验证了“报告偏差”——人类在描述图像时系统性省略隐含推理信息——是导致VLM推理能力缺失的根本原因，并证明单纯扩大规模无法克服该偏差。

🛎️加州大学伯克利分校
🔸2602.22661v1：提出了dLLM——首个开源、模块化、端到端统一的扩散语言建模框架，涵盖训练、推理与评估全流程，并提供轻量级从零构建和模型转换方案。
