[
    {
        "title": "IMMACULATE: A Practical LLM Auditing Framework via Verifiable Computation",
        "authors": [
            "Yanpei Guo",
            "Wenjie Qu",
            "Linyu Wu",
            "Shengfang Zhai",
            "Lionel Z. Wang",
            "Ming Xu",
            "Yue Liu",
            "Binhang Yuan",
            "Dawn Song",
            "Jiaheng Zhang"
        ],
        "categories": [
            "cs.CR",
            "cs.AI"
        ],
        "published_date": "2026-02-26",
        "arxiv_id": "2602.22700v1",
        "pdf_url": "https://arxiv.org/pdf/2602.22700v1",
        "summary": "Commercial large language models are typically deployed as black-box API services, requiring users to trust providers to execute inference correctly and report token usage honestly. We present IMMACULATE, a practical auditing framework that detects economically motivated deviations-such as model substitution, quantization abuse, and token overbilling-without trusted hardware or access to model internals. IMMACULATE selectively audits a small fraction of requests using verifiable computation, achieving strong detection guarantees while amortizing cryptographic overhead. Experiments on dense and MoE models show that IMMACULATE reliably distinguishes benign and malicious executions with under 1% throughput overhead. Our code is published at https://github.com/guo-yanpei/Immaculate.",
        "tag": "å¤§æ¨¡å‹å®¡è®¡",
        "success": true,
        "file_path": "./output/2026-02-26/papers\\2602.22700v1ã€å¤§æ¨¡å‹å®¡è®¡-æ–°åŠ å¡å›½ç«‹å¤§å­¦ã€‘IMMACULATE_ A Practical LLM Auditing Framework via Verifiable Computation.pdf",
        "institution_status": "keep",
        "institution": "æ–°åŠ å¡å›½ç«‹å¤§å­¦ã€å—æ´‹ç†å·¥å¤§å­¦",
        "first_institution": "æ–°åŠ å¡å›½ç«‹å¤§å­¦",
        "institution_category": "å›½å¤–å­¦æœ¯ç•Œ",
        "note": "ğŸ“–æ ‡é¢˜ï¼šIMMACULATE: A Practical LLM Auditing Framework via Verifiable Computation\nğŸŒæ¥æºï¼šarXiv, 2602.22700v1\n\nç¬”è®°æ ‡é¢˜ï¼šå®ç”¨é»‘ç®±å¤§æ¨¡å‹å®¡è®¡æ¡†æ¶\n\nğŸ›ï¸æ–‡ç« ç®€ä»‹  \nğŸ”¸ç ”ç©¶é—®é¢˜ï¼šå¦‚ä½•åœ¨ä¸ä¾èµ–å¯ä¿¡ç¡¬ä»¶ã€ä¸è®¿é—®æ¨¡å‹å†…éƒ¨å‚æ•°çš„å‰æä¸‹ï¼Œé«˜æ•ˆæ£€æµ‹å•†ä¸šå¤§è¯­è¨€æ¨¡å‹APIæœåŠ¡ä¸­çš„ç»æµæ€§ä½œå¼Šè¡Œä¸ºï¼ˆå¦‚æ¨¡å‹æ›¿æ¢ã€æ¿€è¿›é‡åŒ–ã€tokenå¤šè®¡è´¹ï¼‰ï¼Ÿ  \nğŸ”¸ä¸»è¦è´¡çŒ®ï¼šæå‡ºIMMACULATEæ¡†æ¶ï¼Œé¦–æ¬¡å°†æ¦‚ç‡åŒ–æŠ½æ ·å®¡è®¡ä¸å¯éªŒè¯è®¡ç®—ç»“åˆï¼Œå¹¶è®¾è®¡Logitè·ç¦»åˆ†å¸ƒï¼ˆLDDï¼‰ä½œä¸ºæŠ—æµ®ç‚¹éç¡®å®šæ€§çš„å¯éªŒè¯åº¦é‡ï¼Œå®ç°ä½å¼€é”€ã€å¼ºä¿è¯ã€å…¨å…¼å®¹çš„é»‘ç®±LLMå®¡è®¡ã€‚\n\nğŸ“é‡ç‚¹æ€è·¯  \nğŸ”¸é‡‡ç”¨éšæœºåŒ–æŠ½æ ·å®¡è®¡ç­–ç•¥ï¼Œä»…å¯¹æå°æ¯”ä¾‹ï¼ˆå¦‚åƒåˆ†ä¹‹ä¸€ï¼‰çš„ç”¨æˆ·è¯·æ±‚ç”Ÿæˆå¯†ç å­¦è¯æ˜ï¼Œä½¿è¯æ˜å¼€é”€è¢«æµ·é‡æ—¥å¸¸è¯·æ±‚æ‘Šè–„è‡³å¯å¿½ç•¥æ°´å¹³ã€‚  \nğŸ”¸æå‡ºLogitè·ç¦»åˆ†å¸ƒï¼ˆLDDï¼‰æŒ‡æ ‡ï¼Œé€šè¿‡æ¯”å¯¹éƒ¨ç½²æ¨¡å‹ä¸å…¨ç²¾åº¦å‚è€ƒæ¨¡å‹åœ¨å„ç¦»æ•£å†³ç­–æ­¥äº§ç”Ÿçš„logitsè·ç¦»åˆ†å¸ƒï¼Œå°†ä¸å¯éªŒè¯çš„å®Œæ•´æ‰§è¡Œè½¬åŒ–ä¸ºå¯éªŒè¯çš„ç»Ÿè®¡æŒ‡çº¹ã€‚  \nğŸ”¸å¼•å…¥æ§åˆ¶æµå¯¹é½æœºåˆ¶ï¼Œåœ¨å›ºå®šç¦»æ•£é€‰æ‹©ï¼ˆå¦‚tokené‡‡æ ·ç»“æœï¼‰å‰æä¸‹è®¡ç®—logitsåå·®ï¼Œè§„é¿å› å¾®å°æ•°å€¼è¯¯å·®å¯¼è‡´è·¯å¾„åˆ†å‰å¸¦æ¥çš„ä¸å¯æ¯”æ€§ã€‚  \nğŸ”¸è®¾è®¡Top-Kè·ç¦»ä¼˜åŒ–æ–¹æ¡ˆï¼ŒæœåŠ¡å™¨ä»…éœ€æ‰¿è¯ºè¢«é€‰ä¸­çš„å‰Kä¸ªlogitç´¢å¼•è€Œéå…¨éƒ¨logitså‘é‡ï¼Œå¤§å¹…é™ä½å­˜å‚¨ä¸é€šä¿¡å¼€é”€ã€‚  \nğŸ”¸æ„å»ºç«¯åˆ°ç«¯åè®®ï¼šæ¨¡å‹æ–¹å‘å¸ƒå…¨ç²¾åº¦æ¨¡å‹å“ˆå¸Œæ‰¿è¯ºï¼›æ¨ç†æ—¶è®°å½•å¹¶æ‰¿è¯ºæ¯æ­¥logitsï¼›å®¡è®¡æ—¶ç”±æœåŠ¡å™¨åœ¨TEEä¸­ç”¨å…¨ç²¾åº¦æ¨¡å‹é‡ç®—logitså¹¶ç”ŸæˆLDDè¯æ˜ã€‚\n\nğŸ”åˆ†ææ€»ç»“  \nğŸ”¸å®éªŒè¡¨æ˜ï¼Œè‰¯æ€§BF16æ‰§è¡Œçš„LDDå‘ˆç°å°–é”é›†ä¸­åˆ†å¸ƒä¸”å°¾éƒ¨è¡°å‡æå¿«ï¼Œè€ŒFP8é‡åŒ–ä½¿å°¾éƒ¨æ¦‚ç‡æå‡2â€“3ä¸ªæ•°é‡çº§ï¼Œæ¨¡å‹æ›¿æ¢æ›´å¯¼è‡´æç«¯å°¾éƒ¨è´¨é‡å¢åŠ è¾¾100å€ä»¥ä¸Šã€‚  \nğŸ”¸åŸºäºLDDå°¾éƒ¨æ¦‚ç‡ï¼ˆå¦‚Pr[TV>0.1]ï¼‰çš„å•è¯·æ±‚åˆ¤åˆ«è§„åˆ™ï¼Œåœ¨æ¨¡å‹æ›¿æ¢æ”»å‡»ä¸‹æ£€æµ‹ç‡è¶…95%ï¼Œåœ¨FP8é‡åŒ–ä¸‹ä»è¾¾1.3%â€“10.3%ï¼Œæ»¡è¶³éšæœºå®¡è®¡æ‰€éœ€çš„æœ€ä½æ£€æµ‹ç‡è¦æ±‚ã€‚  \nğŸ”¸ç†è®ºåˆ†æè¯å®ï¼šå¯¹Î±=10%æ¶æ„æœåŠ¡å™¨ï¼Œä»…éœ€çº¦3000æ¬¡å®¡è®¡å³å¯ä»¥>95%æ¦‚ç‡æ£€å‡ºï¼›åœ¨10â»âµçº§è¯¯æŠ¥ç‡ä¸‹ï¼Œæ‹’ç»è¯šå®æœåŠ¡å™¨çš„æ¦‚ç‡ä½äº10â»â·ï¼Œæ»¡è¶³å¼ºå®Œå¤‡æ€§ä¸å¯é æ€§ã€‚  \nğŸ”¸åœ¨vLLMä¸Šå®ç°çš„åŸå‹ç³»ç»Ÿå¯¹LLaMA3-70Bç­‰ä¸»æµæ¨¡å‹å¼•å…¥å¹³å‡ä»…0.3%â€“1.0%ååæŸè€—ï¼ŒéªŒè¯äº†å…¶å·¥ç¨‹å®ç”¨æ€§ã€‚  \nğŸ”¸LDDå¯¹å¤šç§è·ç¦»åº¦é‡ï¼ˆTVã€KLã€Top-Kï¼‰å’Œæ¨¡å‹æ¶æ„ï¼ˆDense/MoEï¼‰å‡ä¿æŒç¨³å®šåŒºåˆ†èƒ½åŠ›ï¼Œè¯æ˜å…¶æ³›åŒ–æ€§ä¸é²æ£’æ€§ã€‚\n\nğŸ’¡ä¸ªäººè§‚ç‚¹  \nè¯¥å·¥ä½œåˆ›æ–°æ€§åœ°è·³å‡ºâ€œé€æ¯”ç‰¹å¤ç°â€çš„ä¼ ç»ŸéªŒè¯èŒƒå¼ï¼Œè½¬è€Œæ„å»ºé¢å‘LLMç‰¹æ€§çš„è¯­ä¹‰çº§å¯éªŒè¯æŒ‡çº¹â€”â€”LDDï¼Œå·§å¦™åŒ–è§£æµ®ç‚¹éç¡®å®šæ€§è¿™ä¸€æ ¹æœ¬éšœç¢ï¼›å…¶â€œç»æµé©±åŠ¨çš„æŠ½æ£€+ç»Ÿè®¡å¯è¯â€çš„è®¾è®¡ï¼Œé¦–æ¬¡åœ¨å®Œå¤‡æ€§ã€æ•ˆç‡ä¸éšç§é—´å–å¾—å®è´¨æ€§å¹³è¡¡ï¼Œä¸ºé»‘ç®±AIæœåŠ¡æ²»ç†æä¾›äº†å¯è½åœ°çš„æŠ€æœ¯è·¯å¾„ã€‚\n    "
    },
    {
        "title": "ParamMem: Augmenting Language Agents with Parametric Reflective Memory",
        "authors": [
            "Tianjun Yao",
            "Yongqiang Chen",
            "Yujia Zheng",
            "Pan Li",
            "Zhiqiang Shen",
            "Kun Zhang"
        ],
        "categories": [
            "cs.LG",
            "cs.MA"
        ],
        "published_date": "2026-02-26",
        "arxiv_id": "2602.23320v1",
        "pdf_url": "https://arxiv.org/pdf/2602.23320v1",
        "summary": "Self-reflection enables language agents to iteratively refine solutions, yet often produces repetitive outputs that limit reasoning performance. Recent studies have attempted to address this limitation through various approaches, among which increasing reflective diversity has shown promise. Our empirical analysis reveals a strong positive correlation between reflective diversity and task success, further motivating the need for diverse reflection signals. We introduce ParamMem, a parametric memory module that encodes cross-sample reflection patterns into model parameters, enabling diverse reflection generation through temperature-controlled sampling. Building on this module, we propose ParamAgent, a reflection-based agent framework that integrates parametric memory with episodic and cross-sample memory. Extensive experiments on code generation, mathematical reasoning, and multi-hop question answering demonstrate consistent improvements over state-of-the-art baselines. Further analysis reveals that ParamMem is sample-efficient, enables weak-to-strong transfer across model scales, and supports self-improvement without reliance on stronger external model, highlighting the potential of ParamMem as an effective component for enhancing language agents.",
        "tag": "Agent è®°å¿†",
        "success": true,
        "file_path": "./output/2026-02-26/papers\\2602.23320v1ã€Agent è®°å¿†-å¡å†…åŸºæ¢…éš†å¤§å­¦ã€‘ParamMem_ Augmenting Language Agents with Parametric Reflective Memory.pdf",
        "institution_status": "keep",
        "institution": "å¡å†…åŸºæ¢…éš†å¤§å­¦ã€Mohamed bin Zayed University of Artificial Intelligenceã€Georgia Institute of Technology",
        "first_institution": "å¡å†…åŸºæ¢…éš†å¤§å­¦",
        "institution_category": "å›½å¤–å­¦æœ¯ç•Œ",
        "note": "ğŸ“–æ ‡é¢˜ï¼šParamMem: Augmenting Language Agents with Parametric Reflective Memory\nğŸŒæ¥æºï¼šarXiv, 2602.23320v1\n\nç¬”è®°æ ‡é¢˜ï¼šå‚æ•°åŒ–è®°å¿†å¢å¼ºåæ€å¤šæ ·æ€§\n\nğŸ›ï¸æ–‡ç« ç®€ä»‹  \nğŸ”¸ç ”ç©¶é—®é¢˜ï¼šå¦‚ä½•è¿›ä¸€æ­¥æ‰©å¤§è¯­è¨€ä»£ç†çš„åæ€å¤šæ ·æ€§ä»¥æå‡æ¨ç†æ€§èƒ½ï¼Ÿ  \nğŸ”¸ä¸»è¦è´¡çŒ®ï¼šæå‡ºParamMemâ€”â€”ä¸€ç§å°†è·¨æ ·æœ¬åæ€æ¨¡å¼ç¼–ç è¿›æ¨¡å‹å‚æ•°çš„è½»é‡çº§å‚æ•°åŒ–è®°å¿†æ¨¡å—ï¼Œé€šè¿‡æ¸©åº¦æ§åˆ¶é‡‡æ ·ç”Ÿæˆå¤šæ ·åŒ–åæ€ä¿¡å·ï¼Œæ˜¾è‘—æå‡è¯­è¨€ä»£ç†çš„æ¨ç†èƒ½åŠ›ã€‚\n\nğŸ“é‡ç‚¹æ€è·¯  \nğŸ”¸æ„å»ºè¾…åŠ©åæ€æ•°æ®é›†D={(x_i, rg_i)}ï¼Œå…¶ä¸­rg_iç”±å¼ºLLMï¼ˆå¦‚GPT-4o-miniï¼‰å¯¹è¾“å…¥x_iç”Ÿæˆçš„ç»“æ„åŒ–åæ€ï¼ˆç¼–ç¨‹ä»»åŠ¡å«é”™è¯¯æšä¸¾ã€æ•°å­¦ä»»åŠ¡å«æ¨å¯¼é™·é˜±ã€å¤šè·³QAå«è¯­ä¹‰åˆ†è§£å•å…ƒï¼‰æ„æˆã€‚  \nğŸ”¸é‡‡ç”¨LoRAé«˜æ•ˆå¾®è°ƒè½»é‡LLMï¼ˆå¦‚Llama-3.1-8Bï¼‰ä½œä¸ºParamMemæ¨¡å—M_gï¼Œä½¿å…¶éšå¼å­¦ä¹ è·¨æ ·æœ¬åæ€è§„å¾‹ï¼Œè€Œéä¾èµ–æç¤ºæ¨¡æ¿æˆ–æ£€ç´¢ç›¸ä¼¼æ ·æœ¬ã€‚  \nğŸ”¸åœ¨åå°„æ¡†æ¶ä¸­ï¼Œæ¯è½®è¿­ä»£é™¤ä½¿ç”¨å†å²è‡ªåæ€r_{1:kâˆ’1}å¤–ï¼Œé¢å¤–é‡‡æ ·ParamMemè¾“å‡ºrg_kï¼ˆæ¸©åº¦T=0.2é¦–è½®ã€T=1.0åç»­è½®ï¼‰ï¼Œä¸actoræ¨¡å‹è”åˆæ¡ä»¶ç”Ÿæˆy_kã€‚  \nğŸ”¸æå‡ºParamAgentï¼ˆèåˆæ—¶åºè®°å¿†+å‚æ•°åŒ–è®°å¿†ï¼‰å’ŒParamAgent-plusï¼ˆä¸‰é‡è®°å¿†ï¼šæ—¶åº+è·¨æ ·æœ¬+å‚æ•°åŒ–ï¼‰ï¼Œç»Ÿä¸€å»ºæ¨¡ä¸åŒè®°å¿†æºçš„äº’è¡¥æ€§ã€‚  \nğŸ”¸æ”¯æŒæ— éœ€å¤–éƒ¨å¼ºæ¨¡å‹çš„è‡ªæ”¹è¿›ï¼šç”¨åŸºæ¨¡å‹è‡ªèº«ç”Ÿæˆçš„æ•°æ®è®­ç»ƒParamMemï¼Œä»èƒ½æŒç»­æå‡æ€§èƒ½ï¼›ä¸”å°æ¨¡å‹ParamMemå¯æœ‰æ•ˆå¢å¼ºå¤§æ¨¡å‹agentï¼ˆå¼±åˆ°å¼ºè¿ç§»ï¼‰ã€‚\n\nğŸ”åˆ†ææ€»ç»“  \nğŸ”¸åæ€å¤šæ ·æ€§ï¼ˆå¹³å‡æˆå¯¹ä½™å¼¦è·ç¦»ï¼‰ä¸ä»»åŠ¡å‡†ç¡®ç‡å‘ˆå¼ºæ­£ç›¸å…³ï¼ˆå¹³å‡r=0.76ï¼‰ï¼ŒéªŒè¯æå‡å¤šæ ·æ€§æ˜¯å…³é”®ä¼˜åŒ–æ–¹å‘ã€‚  \nğŸ”¸ParamMemæ˜¾è‘—å¢åŠ åæ€èšç±»æ•°ï¼ˆK*=39 vs Reflexionçš„32ï¼‰ä¸è½®å»“ç³»æ•°ï¼Œè¯æ˜å…¶å¼•å…¥äº†ç‹¬ç«‹äºæ—¶åº/è·¨æ ·æœ¬è®°å¿†çš„æ–°é¢–è¯­ä¹‰å¤šæ ·æ€§å±‚ã€‚  \nğŸ”¸å¤šæ ·åæ€æ‰©å±•äº†é”™è¯¯è¯Šæ–­çš„å‡è®¾ç©ºé—´ï¼Œä½¿agentæ›´å¯èƒ½æ•è·æ­£ç¡®ä¿®æ­£çº¿ç´¢ï¼Œå°¤å…¶åœ¨Reflexion/DoTå¤±è´¥æ¡ˆä¾‹ä¸­ä½“ç°æ˜æ˜¾ã€‚  \nğŸ”¸ä»…éœ€çº¦500ä¸ªK-meansé‡‡æ ·çš„å¤šæ ·æ ·æœ¬å³å¯è¾¾åˆ°ä¼˜å¼‚æ€§èƒ½ï¼ŒParamAgent-plusç”¨500æ ·æœ¬å³è¶…è¶Šç”¨8000æ ·æœ¬è®­ç»ƒçš„ParamAgentï¼Œå‡¸æ˜¾æ ·æœ¬æ•ˆç‡ã€‚  \nğŸ”¸ParamMemæ”¯æŒå¼±åˆ°å¼ºè¿ç§»ï¼š8B ParamMemå¯æå‡70BåŸºæ¨¡å‹æ€§èƒ½ï¼›ä¸”æ— éœ€å¼ºæ¨¡å‹æ ‡æ³¨ï¼Œä»…ç”¨åŸºæ¨¡å‹è‡ªäº§æ•°æ®å³å¯å®ç°è‡ªæˆ‘æ”¹è¿›ã€‚\n\nğŸ’¡ä¸ªäººè§‚ç‚¹  \nè®ºæ–‡åˆ›æ–°ç‚¹åœ¨äºè·³å‡ºâ€œæç¤ºå·¥ç¨‹â€ä¸â€œæ£€ç´¢å¢å¼ºâ€çš„ä¼ ç»ŸèŒƒå¼ï¼Œé¦–æ¬¡å°†åæ€å¤šæ ·æ€§å»ºæ¨¡ä¸ºå¯å­¦ä¹ çš„å‚æ•°åŒ–è®°å¿†ï¼Œä»¥è½»é‡å¾®è°ƒæ–¹å¼å†…åŒ–è·¨æ ·æœ¬å…±æ€§æ¨¡å¼ã€‚å…¶æ ¸å¿ƒæ´è§æ˜¯ï¼šå¤šæ ·æ€§æœ¬è´¨æ˜¯æ³›åŒ–èƒ½åŠ›ï¼Œè€Œéç®€å•æ£€ç´¢æˆ–éšæœºæ‰°åŠ¨ï¼›ParamMemé€šè¿‡å‚æ•°åŒ–ç¼–ç å®ç°æ¨¡å¼æ’å€¼ä¸å¤–æ¨ï¼Œå…¼å…·é«˜æ•ˆæ€§ã€å¯è¿ç§»æ€§ä¸è‡ªæŒæ€§ï¼Œä¸ºæ„å»ºå¯æŒç»­è¿›åŒ–çš„è¯­è¨€ä»£ç†æä¾›äº†æ–°åŸºç¡€è®¾æ–½ã€‚\n    "
    },
    {
        "title": "Scale Can't Overcome Pragmatics: The Impact of Reporting Bias on Vision-Language Reasoning",
        "authors": [
            "Amita Kamath",
            "Jack Hessel",
            "Khyathi Chandu",
            "Jena D. Hwang",
            "Kai-Wei Chang",
            "Ranjay Krishna"
        ],
        "categories": [
            "cs.CL",
            "cs.CV"
        ],
        "published_date": "2026-02-26",
        "arxiv_id": "2602.23351v1",
        "pdf_url": "https://arxiv.org/pdf/2602.23351v1",
        "summary": "The lack of reasoning capabilities in Vision-Language Models (VLMs) has remained at the forefront of research discourse. We posit that this behavior stems from a reporting bias in their training data. That is, how people communicate about visual content by default omits tacit information needed to supervise some types of reasoning; e.g., \"at the game today!\" is a more likely caption than \"a photo of 37 people standing behind a field\". We investigate the data underlying the popular VLMs OpenCLIP, LLaVA-1.5 and Molmo through the lens of theories from pragmatics, and find that reporting bias results in insufficient representation of four reasoning skills (spatial, temporal, negation, and counting), despite the corpora being of web-scale, and/or synthetically generated. With a set of curated benchmarks, we demonstrate that: (i) VLMs perform poorly on the aforementioned types of reasoning suppressed in the training data by reporting bias; (ii) contrary to popular belief, scaling data size, model size, and to multiple languages does not result in emergence of these skills by default; but, promisingly, (iii) incorporating annotations specifically collected to obtain tacit information is effective. Our findings highlight the need for more intentional training data curation methods, rather than counting on scale for emergence of reasoning capabilities.",
        "tag": "è®­ç»ƒæ•°æ®åå·®",
        "success": true,
        "file_path": "./output/2026-02-26/papers\\2602.23351v1ã€è®­ç»ƒæ•°æ®åå·®-åç››é¡¿å¤§å­¦ã€‘Scale Can't Overcome Pragmatics_ The Impact of Reporting Bias on Vision-Language Reasoning.pdf",
        "institution_status": "keep",
        "institution": "åç››é¡¿å¤§å­¦ã€åŠ å·å¤§å­¦æ´›æ‰çŸ¶åˆ†æ ¡ã€Samaya AIã€Mistral AIã€AllenAI",
        "first_institution": "åç››é¡¿å¤§å­¦",
        "institution_category": "å›½å¤–å­¦æœ¯ç•Œ",
        "note": "ğŸ“–æ ‡é¢˜ï¼šScale Can't Overcome Pragmatics: The Impact of Reporting Bias on Vision-Language Reasoning\nğŸŒæ¥æºï¼šarXiv, 2602.23351v1\n\nç¬”è®°æ ‡é¢˜ï¼šæŠ¥å‘Šåå·®é˜»ç¢è§†è§‰è¯­è¨€æ¨ç†\n\nğŸ›ï¸æ–‡ç« ç®€ä»‹  \nğŸ”¸ç ”ç©¶é—®é¢˜ï¼šä¸ºä»€ä¹ˆå½“å‰å¤§è§„æ¨¡è§†è§‰è¯­è¨€æ¨¡å‹åœ¨ç©ºé—´ã€æ—¶é—´ã€å¦å®šå’Œè®¡æ•°ç­‰åŸºç¡€æ¨ç†ä»»åŠ¡ä¸Šè¡¨ç°è¿œé€Šäºäººç±»ï¼Œå³ä½¿æ•°æ®å’Œæ¨¡å‹è§„æ¨¡æŒç»­æ‰©å¤§ï¼Ÿ  \nğŸ”¸ä¸»è¦è´¡çŒ®ï¼šé¦–æ¬¡ç³»ç»Ÿæ­ç¤ºå¹¶éªŒè¯äº†â€œæŠ¥å‘Šåå·®â€â€”â€”äººç±»åœ¨æè¿°å›¾åƒæ—¶ç³»ç»Ÿæ€§çœç•¥éšå«æ¨ç†ä¿¡æ¯â€”â€”æ˜¯å¯¼è‡´VLMæ¨ç†èƒ½åŠ›ç¼ºå¤±çš„æ ¹æœ¬åŸå› ï¼Œå¹¶è¯æ˜å•çº¯æ‰©å¤§è§„æ¨¡æ— æ³•å…‹æœè¯¥åå·®ã€‚\n\nğŸ“é‡ç‚¹æ€è·¯  \nğŸ”¸åŸºäºè¯­ç”¨å­¦ï¼ˆGriceä¼šè¯å‡†åˆ™ï¼‰å’Œè®¤çŸ¥è¯­è¨€å­¦ç†è®ºï¼Œæå‡ºå››ç±»è¢«æ™®éçœç•¥çš„æ¨ç†ç±»å‹ï¼šç©ºé—´å…³ç³»ï¼ˆå¦‚â€œå·¦/å³â€ï¼‰ã€æ—¶é—´é¡ºåºï¼ˆå¦‚â€œä¹‹å‰/ä¹‹åâ€ï¼‰ã€å¦å®šè¡¨è¾¾ï¼ˆå¦‚â€œæ²¡æœ‰â€¦â€¦â€ï¼‰å’Œç²¾ç¡®è®¡æ•°ã€‚  \nğŸ”¸é€šè¿‡å…³é”®è¯æ£€ç´¢ä¸äººå·¥æ ¡éªŒï¼Œåœ¨LAIONã€LLaVA-1.5ã€Molmoç­‰ä¸‰å¤§å¼€æºå¤šæ¨¡æ€æ•°æ®é›†ä¸Šå®è¯å››ç±»æ¨ç†è¡¨è¾¾çš„å‡ºç°ç‡æä½ï¼ˆå¦‚LAIONä¸­ç©ºé—´å…³ç³»ä»…çº¦0.1%ï¼‰ï¼Œè¯å®æŠ¥å‘Šåå·®æ™®éå­˜åœ¨ã€‚  \nğŸ”¸æ„å»ºå››ä¸ªé’ˆå¯¹æ€§åŸºå‡†ï¼ˆSpatial/Counting/Negation/Temporalï¼‰ï¼Œç»Ÿä¸€é‡‡ç”¨å¤šé€‰é¢˜å›¾åƒ-æ–‡æœ¬åŒ¹é…èŒƒå¼ï¼Œè¦†ç›–å¯¹æ¯”å¼ä¸ç”Ÿæˆå¼VLMï¼Œå®ç°è·¨æ¨¡å‹å…¬å¹³è¯„ä¼°ã€‚  \nğŸ”¸è®¾è®¡å—æ§ç”¨æˆ·å®éªŒï¼šå›ºå®šCOCOå›¾åƒé›†ï¼Œå¯¹æ¯”ä¸åŒæ ‡æ³¨æŒ‡ä»¤ï¼ˆCOCOåŸæŒ‡ä»¤ã€LLaVAã€PixMoåŠæœ¬æ–‡æ–°æŒ‡ä»¤ï¼‰å¯¹å››ç±»æ¨ç†è¡¨è¾¾äº§å‡ºç‡çš„å½±å“ï¼ŒéªŒè¯æŒ‡ä»¤å¯å®šå‘ç¼“è§£åå·®ã€‚  \nğŸ”¸å¼€å±•å¾®è°ƒå®éªŒï¼Œå°†æŒ‰æ–°æŒ‡ä»¤ç”Ÿæˆçš„é«˜æ¨ç†å¯†åº¦æ•°æ®ï¼ˆ39%è®¡æ•°ï¼‰æ³¨å…¥LLaVA-1.5è®­ç»ƒï¼Œè¯å®å…¶æ˜¾è‘—æå‡æ¨¡å‹è®¡æ•°æ€§èƒ½ï¼ŒéªŒè¯æ•°æ®å¹²é¢„çš„æœ‰æ•ˆæ€§ã€‚\n\nğŸ”åˆ†ææ€»ç»“  \nğŸ”¸æ‰€æœ‰ä¸»æµVLMï¼ˆåŒ…æ‹¬CLIPç³»åˆ—ã€LLaVAã€Molmoã€Qwen-VLåŠé—­æºGPT-4o/Geminiï¼‰åœ¨å››ç±»æ¨ç†ä»»åŠ¡ä¸Šå¹³å‡è½åäººç±»æ€§èƒ½è¾¾54åˆ†ï¼Œå°¤å…¶å¦å®šä»»åŠ¡æ¥è¿‘éšæœºæ°´å¹³ã€‚  \nğŸ”¸æ¨¡å‹ä¸æ•°æ®è§„æ¨¡æ‰©å¤§ï¼ˆå‚æ•°é‡ã€æ•°æ®é‡ã€å¤šè¯­è¨€ç¿»è¯‘ï¼‰å‡æœªå¸¦æ¥æ¨ç†èƒ½åŠ›çš„â€œæ¶Œç°â€ï¼Œç¼©æ”¾å®šå¾‹æ˜¾ç¤ºæŸå¤±å‡ ä¹ä¸éšè®¡ç®—é‡å¢åŠ è€Œä¸‹é™ï¼Œè¯æ˜åå·®æœ¬è´¨æ˜¯æ•°æ®ç”Ÿæˆæœºåˆ¶é—®é¢˜è€Œéè§„æ¨¡ä¸è¶³ã€‚  \nğŸ”¸æŠ¥å‘Šåå·®åŒæ ·å­˜åœ¨äºLLMåˆæˆæ•°æ®ï¼ˆå¦‚LLaVA-1.5ä¸­GPT-4ç”Ÿæˆéƒ¨åˆ†ï¼‰ï¼Œè¯´æ˜è¯­è¨€æ¨¡å‹ç»§æ‰¿å¹¶æ”¾å¤§äº†äººç±»åå·®ï¼ŒæŒ‡ä»¤è®¾è®¡å¯¹åˆæˆæ•°æ®åŒæ ·å…³é”®ã€‚  \nğŸ”¸æ ‡æ³¨æŒ‡ä»¤ç›´æ¥å½±å“æ¨ç†è¡¨è¾¾å¯†åº¦ï¼šæœ¬æ–‡æ–°æŒ‡ä»¤ä½¿å¦å®šä¸æ—¶é—´è¡¨è¾¾ç‡ä»0%è·ƒå‡è‡³52%å’Œ44%ï¼Œè€Œä»…å»¶é•¿å­—æ•°ï¼ˆ50è¯ï¼‰æ— æ³•æ¿€å‘è¢«é»˜è®¤å¿½ç•¥çš„æ¨ç†ç±»å‹ã€‚  \nğŸ”¸è®­ç»ƒæ•°æ®ä¸­æ¨ç†æ¦‚å¿µçš„çœŸå®è¦†ç›–ç‡ä¸æ¨¡å‹æ€§èƒ½å‘ˆå¼ºæ­£ç›¸å…³ï¼Œä¸”å¾®è°ƒå®éªŒè¯æ˜ï¼Œæå‡è¦†ç›–ç‡å¯ç›´æ¥æ”¹å–„æ¨¡å‹èƒ½åŠ›ï¼Œç¡®è®¤åå·®æ˜¯å¯å¹²é¢„çš„æ•°æ®è´¨é‡é—®é¢˜ã€‚\n\nğŸ’¡ä¸ªäººè§‚ç‚¹  \nè®ºæ–‡åˆ›æ–°ç‚¹åœ¨äºå°†è¯­è¨€å­¦ä¸­çš„â€œæŠ¥å‘Šåå·®â€ç†è®ºé¦–æ¬¡æ·±åº¦è¿ç§»åˆ°å¤šæ¨¡æ€é¢†åŸŸï¼Œä¸ä»…æŒ‡å‡ºé—®é¢˜ï¼Œæ›´é€šè¿‡è·¨å­¦ç§‘ç†è®ºå»ºæ¨¡ã€å¤šç»´åº¦å®è¯æ£€éªŒä¸å¯å¤ç°å¹²é¢„å®éªŒï¼Œç¡®ç«‹äº†â€œæ•°æ®ç”Ÿæˆæœºåˆ¶ç¼ºé™·â€æ¯”â€œæ¨¡å‹æ¶æ„é™åˆ¶â€æ›´æ ¹æœ¬çš„å½’å› ï¼›å…¶æ ¸å¿ƒæ´è§â€”â€”â€œäººç±»äº¤æµçš„ç»æµæ€§åŸåˆ™å¤©ç„¶æ’æ–¥æ¨ç†å†—ä½™ï¼Œå› æ­¤å¿…é¡»ä¸»åŠ¨è®¾è®¡æ•°æ®é‡‡é›†è§„åˆ™â€â€”â€”ä¸ºå¤šæ¨¡æ€åŸºç¡€æ¨¡å‹å‘å±•æä¾›äº†èŒƒå¼çº§å¯ç¤ºï¼šé«˜è´¨é‡æ¨ç†èƒ½åŠ›æ— æ³•é è§„æ¨¡å †ç Œï¼Œè€Œéœ€åœ¨æ•°æ®æºå¤´åµŒå…¥è®¤çŸ¥æ„è¯†ã€‚\n    "
    },
    {
        "title": "Strategy Executability in Mathematical Reasoning: Leveraging Human-Model Differences for Effective Guidance",
        "authors": [
            "Weida Liang",
            "Yiyou Sun",
            "Shuyuan Nan",
            "Chuang Li",
            "Dawn Song",
            "Kenji Kawaguchi"
        ],
        "categories": [
            "cs.AI",
            "cs.CL"
        ],
        "published_date": "2026-02-26",
        "arxiv_id": "2602.22583v1",
        "pdf_url": "https://arxiv.org/pdf/2602.22583v1",
        "summary": "Example-based guidance is widely used to improve mathematical reasoning at inference time, yet its effectiveness is highly unstable across problems and models-even when the guidance is correct and problem-relevant. We show that this instability arises from a previously underexplored gap between strategy usage-whether a reasoning strategy appears in successful solutions-and strategy executability-whether the strategy remains effective when instantiated as guidance for a target model. Through a controlled analysis of paired human-written and model-generated solutions, we identify a systematic dissociation between usage and executability: human- and model-derived strategies differ in structured, domain-dependent ways, leading to complementary strengths and consistent source-dependent reversals under guidance. Building on this diagnosis, we propose Selective Strategy Retrieval (SSR), a test-time framework that explicitly models executability by selectively retrieving and combining strategies using empirical, multi-route, source-aware signals. Across multiple mathematical reasoning benchmarks, SSR yields reliable and consistent improvements over direct solving, in-context learning, and single-source guidance, improving accuracy by up to $+13$ points on AIME25 and $+5$ points on Apex for compact reasoning models. Code and benchmark are publicly available at: https://github.com/lwd17/strategy-execute-pipeline.",
        "tag": "æ¨ç†ç­–ç•¥ä¼˜åŒ–",
        "success": true,
        "file_path": "./output/2026-02-26/papers\\2602.22583v1ã€æ¨ç†ç­–ç•¥ä¼˜åŒ–-æ–°åŠ å¡å›½ç«‹å¤§å­¦ã€‘Strategy Executability in Mathematical Reasoning_ Leveraging Human-Model Differences for Effective Guidance.pdf",
        "institution_status": "keep",
        "institution": "æ–°åŠ å¡å›½ç«‹å¤§å­¦ã€åŠ å·å¤§å­¦ä¼¯å…‹åˆ©åˆ†æ ¡",
        "first_institution": "æ–°åŠ å¡å›½ç«‹å¤§å­¦",
        "institution_category": "å›½å¤–å­¦æœ¯ç•Œ",
        "note": "ğŸ“–æ ‡é¢˜ï¼šStrategy Executability in Mathematical Reasoning: Leveraging Human-Model Differences for Effective Guidance\nğŸŒæ¥æºï¼šarXiv, 2602.22583v1\n\nç¬”è®°æ ‡é¢˜ï¼šç­–ç•¥å¯æ‰§è¡Œæ€§å»ºæ¨¡\n\nğŸ›ï¸æ–‡ç« ç®€ä»‹  \nğŸ”¸ç ”ç©¶é—®é¢˜ï¼šä¸ºä»€ä¹ˆæ­£ç¡®ä¸”ç›¸å…³çš„é—®é¢˜æ±‚è§£ç­–ç•¥åœ¨ä½œä¸ºæ¨ç†å¼•å¯¼æ—¶ä»å¸¸å¤±æ•ˆï¼Ÿ  \nğŸ”¸ä¸»è¦è´¡çŒ®ï¼šæå‡ºâ€œç­–ç•¥å¯æ‰§è¡Œæ€§â€æ–°æ¦‚å¿µï¼Œæ­ç¤ºç­–ç•¥åœ¨äººç±»è§£æ³•ä¸­å‡ºç°ä¸åœ¨æ¨¡å‹ä¸ŠæˆåŠŸå¼•å¯¼ä¹‹é—´çš„ç³»ç»Ÿæ€§è„±èŠ‚ï¼Œå¹¶æ®æ­¤è®¾è®¡è½»é‡çº§æµ‹è¯•æ—¶æ¡†æ¶SSRã€‚\n\nğŸ“é‡ç‚¹æ€è·¯  \nğŸ”¸å®šä¹‰ç­–ç•¥å¯æ‰§è¡Œæ€§ä¸ºç­–ç•¥åœ¨å›ºå®šæç¤ºä¸è§£ç æ¡ä»¶ä¸‹æå‡ç›®æ ‡æ¨¡å‹æ­£ç¡®ç‡çš„èƒ½åŠ›ï¼ŒåŒºåˆ«äºå•çº¯ç»Ÿè®¡ç­–ç•¥åœ¨æˆåŠŸè§£æ³•ä¸­çš„å‡ºç°é¢‘ç‡ï¼ˆå³ç­–ç•¥ä½¿ç”¨ï¼‰ã€‚  \nğŸ”¸æ„å»ºHM-ReasoningBenché…å¯¹æ•°æ®é›†ï¼Œç³»ç»Ÿåˆ†æäººç±»ä¸æ¨¡å‹è§£æ³•åœ¨ç­–ç•¥ä½¿ç”¨ä¸Šçš„ç»“æ„åŒ–å·®å¼‚ï¼šäººç±»åå¥½ç»“æ„/å‡ ä½•ç±»ç­–ç•¥ï¼ˆå¦‚è¾…åŠ©çº¿ã€å¯¹ç§°æ€§ï¼‰ï¼Œæ¨¡å‹å€¾å‘ç¨‹åº/ä»£æ•°ç±»ç­–ç•¥ï¼ˆå¦‚åæ ‡è®¾å®šã€åˆ†æƒ…å†µè®¨è®ºï¼‰ã€‚  \nğŸ”¸å‘ç°ç­–ç•¥æ¥æºä¸é¢†åŸŸå¼ºè€¦åˆï¼šäººç±»ç­–ç•¥åœ¨å‡ ä½•/ç»„åˆé¢˜ä¸­æ›´å¯æ‰§è¡Œï¼Œæ¨¡å‹ç­–ç•¥åœ¨ä»£æ•°/æ•°è®ºé¢˜ä¸­æ›´å¯é ï¼Œå•ä¸€æ¥æºå¼•å¯¼æ˜“å¤±è´¥ã€‚  \nğŸ”¸æå‡ºSelective Strategy Retrievalï¼ˆSSRï¼‰ï¼šåŸºäºå¼‚æ„ç­–ç•¥çŸ¥è¯†å›¾å»ºæ¨¡ï¼Œèåˆä¸‰è·¯æ£€ç´¢â€”â€”ç±»åˆ«çº§è§„å¾‹ï¼ˆRoute Aï¼‰ã€é—®é¢˜çº§è¿ç§»ï¼ˆRoute Bï¼‰ã€è¯­ä¹‰å›é€€ï¼ˆRoute Cï¼‰ï¼Œå¹¶ç”¨Beta-Binomialæ ¡å‡†çš„å¯æ‰§è¡Œæ€§é¢„æµ‹å™¨æ’åºç­–ç•¥ã€‚  \nğŸ”¸SSRçº¯æµ‹è¯•æ—¶è¿è¡Œï¼Œæ— éœ€ä¿®æ”¹æ¨¡å‹æˆ–è®­ç»ƒæ•°æ®ï¼Œä»…ä»¥æŠ½è±¡ç­–ç•¥æç¤ºï¼ˆéæ­¥éª¤ç»†èŠ‚ï¼‰å¼•å¯¼ï¼Œä¿æŒçµæ´»æ€§åŒæ—¶åŒ¹é…æ¨¡å‹æ“ä½œä¼˜åŠ¿ã€‚\n\nğŸ”åˆ†ææ€»ç»“  \nğŸ”¸ç­–ç•¥ä½¿ç”¨é¢‘ç‡ä¸èƒ½é¢„æµ‹å…¶å¯æ‰§è¡Œæ€§ï¼šé«˜é¢‘äººç±»ç­–ç•¥ï¼ˆå¦‚è§’è¿½é€ï¼‰åœ¨æ¨¡å‹ä¸Šå¸¸ä¸å¯é ï¼Œè€Œä½é¢‘æ¨¡å‹ç­–ç•¥ï¼ˆå¦‚åæ ‡è®¾å®šï¼‰åè€Œæ›´æ˜“æ‰§è¡Œã€‚  \nğŸ”¸å¯æ‰§è¡Œæ€§å…·æœ‰å¼ºæºä¾èµ–æ€§ä¸é¢†åŸŸç‰¹å¼‚æ€§ï¼šåœ¨å‡ ä½•é¢˜ä¸­ï¼Œäººç±»ç­–ç•¥å¹³å‡å¯æ‰§è¡Œæ€§æ˜¾è‘—é«˜äºæ¨¡å‹ç­–ç•¥ï¼›åœ¨ä»£æ•°é¢˜ä¸­åˆ™ç›¸åã€‚  \nğŸ”¸SSRåœ¨å¤šä¸ªåŸºå‡†ï¼ˆHM-ReasoningBenchã€AIME25ã€APEXï¼‰ä¸Šç¨³å®šè¶…è¶Šç›´æ¥æ±‚è§£ã€ä¸Šä¸‹æ–‡å­¦ä¹ åŠå•æºç­–ç•¥å¼•å¯¼ï¼Œæœ€é«˜æå‡13ç‚¹å‡†ç¡®ç‡ï¼ˆAIME25ï¼‰ï¼Œä¸”åœ¨éš¾é¢˜ä¸Šå¢ç›Šæ›´å¤§ã€‚  \nğŸ”¸æ¶ˆèå®éªŒè¯æ˜ä¸‰è·¯æ£€ç´¢å‡å¿…è¦ï¼šç§»é™¤é—®é¢˜çº§è¿ç§»ï¼ˆRoute Bï¼‰å¯¼è‡´æœ€å¤§æ€§èƒ½ä¸‹é™ï¼Œå‡¸æ˜¾ç»†ç²’åº¦ä¸Šä¸‹æ–‡é€‚é…çš„å…³é”®ä½œç”¨ã€‚  \nğŸ”¸é”™è¯¯æ¨¡å¼åˆ†æè¡¨æ˜ï¼šäººç±»ç­–ç•¥ä¸»è¦ç¼“è§£ç»“æ„æ€§å¤±è´¥ï¼ˆå¦‚æ¼åˆ†è§£ã€ç¼ºä¸å˜é‡ï¼‰ï¼Œæ¨¡å‹ç­–ç•¥æ›´æ“…ä¿®æ­£ä»£æ•°è®¡ç®—é”™è¯¯ï¼ŒSSRäºŒè€…å…¼é¡¾ã€‚\n\nğŸ’¡ä¸ªäººè§‚ç‚¹  \nè®ºæ–‡æ ¸å¿ƒåˆ›æ–°åœ¨äºå°†â€œç­–ç•¥æœ‰æ•ˆæ€§â€ä»é™æ€è¯­ä¹‰æ­£ç¡®æ€§è½¬å‘åŠ¨æ€æ“ä½œå¯è¡Œæ€§ï¼Œé¦–æ¬¡å°†äººç±»ä¸æ¨¡å‹çš„è®¤çŸ¥å·®å¼‚å»ºæ¨¡ä¸ºå¯æ‰§è¡Œæ€§ä¿¡å·æºã€‚å…¶æ–¹æ³•è®ºçªç ´ä½“ç°åœ¨ä¸‰æ–¹é¢ï¼šä¸€æ˜¯æå‡ºå¯æ‰§è¡Œæ€§è¿™ä¸€å¯æµ‹é‡ã€å¯æ ¡å‡†çš„æ“ä½œæ€§æŒ‡æ ‡ï¼›äºŒæ˜¯æ„å»ºé¦–ä¸ªå¸¦äººç±»/æ¨¡å‹åŒæºè§£æ³•çš„ç­–ç•¥çº§é…å¯¹åŸºå‡†HM-ReasoningBenchï¼›ä¸‰æ˜¯è®¾è®¡æºæ„ŸçŸ¥ã€å¤šè·¯å¾„ã€å›¾å¢å¼ºçš„è½»é‡çº§æ£€ç´¢æ¡†æ¶SSRï¼Œä¸å¢åŠ æ¨ç†å¼€é”€å´æ˜¾è‘—æå‡é²æ£’æ€§ã€‚è¯¥è§†è§’æœ‰æœ›æ¨åŠ¨æ¨ç†è¯„ä¼°ä»â€œç­”æ¡ˆå¯¹é”™â€è¿ˆå‘â€œä¸­é—´æŠ½è±¡æ˜¯å¦å¯ç”¨â€ã€‚\n    "
    },
    {
        "title": "dLLM: Simple Diffusion Language Modeling",
        "authors": [
            "Zhanhui Zhou",
            "Lingjie Chen",
            "Hanghang Tong",
            "Dawn Song"
        ],
        "categories": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "published_date": "2026-02-26",
        "arxiv_id": "2602.22661v1",
        "pdf_url": "https://arxiv.org/pdf/2602.22661v1",
        "summary": "Although diffusion language models (DLMs) are evolving quickly, many recent models converge on a set of shared components. These components, however, are distributed across ad-hoc research codebases or lack transparent implementations, making them difficult to reproduce or extend. As the field accelerates, there is a clear need for a unified framework that standardizes these common components while remaining flexible enough to support new methods and architectures.\n  To address this gap, we introduce dLLM, an open-source framework that unifies the core components of diffusion language modeling -- training, inference, and evaluation -- and makes them easy to customize for new designs. With dLLM, users can reproduce, finetune, deploy, and evaluate open-source large DLMs such as LLaDA and Dream through a standardized pipeline. The framework also provides minimal, reproducible recipes for building small DLMs from scratch with accessible compute, including converting any BERT-style encoder or autoregressive LM into a DLM. We also release the checkpoints of these small DLMs to make DLMs more accessible and accelerate future research.",
        "tag": "æ‰©æ•£è¯­è¨€æ¨¡å‹æ¡†æ¶",
        "success": true,
        "file_path": "./output/2026-02-26/papers\\2602.22661v1ã€æ‰©æ•£è¯­è¨€æ¨¡å‹æ¡†æ¶-åŠ å·å¤§å­¦ä¼¯å…‹åˆ©åˆ†æ ¡ã€‘dLLM_ Simple Diffusion Language Modeling.pdf",
        "institution_status": "keep",
        "institution": "åŠ å·å¤§å­¦ä¼¯å…‹åˆ©åˆ†æ ¡ã€ä¼Šåˆ©è¯ºä¼Šå¤§å­¦å„å·´çº³ - é¦™æ§Ÿåˆ†æ ¡",
        "first_institution": "åŠ å·å¤§å­¦ä¼¯å…‹åˆ©åˆ†æ ¡",
        "institution_category": "å›½å¤–å­¦æœ¯ç•Œ",
        "note": "ğŸ“–æ ‡é¢˜ï¼šdLLM: Simple Diffusion Language Modeling\nğŸŒæ¥æºï¼šarXiv, 2602.22661v1\n\nç¬”è®°æ ‡é¢˜ï¼šç»Ÿä¸€æ‰©æ•£è¯­è¨€å»ºæ¨¡æ¡†æ¶\n\nğŸ›ï¸æ–‡ç« ç®€ä»‹  \nğŸ”¸ç ”ç©¶é—®é¢˜ï¼šå¦‚ä½•è§£å†³å½“å‰æ‰©æ•£è¯­è¨€æ¨¡å‹ï¼ˆDLMsï¼‰å› ä»£ç åˆ†æ•£ã€å®ç°ä¸é€æ˜è€Œå¯¼è‡´çš„å¤ç°éš¾ã€æ¯”è¾ƒéš¾ã€æ‰©å±•éš¾é—®é¢˜ï¼Ÿ  \nğŸ”¸ä¸»è¦è´¡çŒ®ï¼šæå‡ºäº†dLLMâ€”â€”é¦–ä¸ªå¼€æºã€æ¨¡å—åŒ–ã€ç«¯åˆ°ç«¯ç»Ÿä¸€çš„æ‰©æ•£è¯­è¨€å»ºæ¨¡æ¡†æ¶ï¼Œæ¶µç›–è®­ç»ƒã€æ¨ç†ä¸è¯„ä¼°å…¨æµç¨‹ï¼Œå¹¶æä¾›è½»é‡çº§ä»é›¶æ„å»ºå’Œæ¨¡å‹è½¬æ¢æ–¹æ¡ˆã€‚\n\nğŸ“é‡ç‚¹æ€è·¯  \nğŸ”¸è®¾è®¡ç»Ÿä¸€Traineræ¥å£ï¼Œæ”¯æŒMasked Diffusionï¼ˆMDLMï¼‰å’ŒBlock Diffusionï¼ˆBD3LMï¼‰ç­‰ä¸»æµç›®æ ‡ï¼Œé€šè¿‡æ¨¡å—åŒ–å°è£…ï¼ˆå¦‚MDLMTrainer/BD3LMTrainerï¼‰å®ç°è®­ç»ƒé€»è¾‘ä¸æ¨¡å‹æ¶æ„è§£è€¦ã€‚  \nğŸ”¸æ„å»ºè½»é‡çº§SampleræŠ½è±¡å±‚ï¼Œä»¥plug-and-playæ–¹å¼è§£è€¦æ¨¡å‹ä¸æ¨ç†ç®—æ³•ï¼Œæ”¯æŒFast-dLLMç­‰é«˜æ•ˆè§£ç å™¨æ— ç¼æ›¿æ¢ï¼Œæ— éœ€ä¿®æ”¹æ¨¡å‹ä»£ç ã€‚  \nğŸ”¸æ‰©å±•lm-evaluation-harnessï¼Œæ„å»ºé«˜ä¿çœŸè¯„ä¼°ç®¡é“ï¼Œä¸¥æ ¼å¤ç°å„æ¨¡å‹å®˜æ–¹é¢„å¤„ç†ã€è§£ç å‚æ•°ä¸åå¤„ç†æµç¨‹ï¼Œç¡®ä¿ç»“æœå¯æ¯”æ€§ã€‚  \nğŸ”¸æä¾›ä¸¤ç±»â€œå¼€ç®±å³ç”¨â€çš„å°è§„æ¨¡DLMæ„å»ºè·¯å¾„ï¼šä¸€æ˜¯å°†BERTå¼ç¼–ç å™¨å¾®è°ƒä¸ºå¯¹è¯å‹DLMï¼ˆBERT-Chatï¼‰ï¼ŒäºŒæ˜¯å°†è‡ªå›å½’LMï¼ˆå¦‚Qwenï¼‰é€šè¿‡SFTç›´æ¥è½¬ä¸ºDLMï¼ˆTiny-A2Dï¼‰ï¼Œå‡æ— éœ€æ¶æ„ä¿®æ”¹æˆ–æŒç»­é¢„è®­ç»ƒã€‚  \nğŸ”¸æ‰€æœ‰ç»„ä»¶åŸºäºHuggingFaceç”Ÿæ€ï¼ˆTransformersã€Accelerateã€PEFTã€DeepSpeedï¼‰ï¼Œå…¼é¡¾æ˜“ç”¨æ€§ä¸å¤§æ¨¡å‹å¯æ‰©å±•æ€§ã€‚\n\nğŸ”åˆ†ææ€»ç»“  \nğŸ”¸dLLMæˆåŠŸå¤ç°LLaDAä¸Dreamç­‰ä¸»æµDLMçš„å®˜æ–¹è¯„æµ‹ç»“æœï¼ˆè¯¯å·®<1.5%ï¼‰ï¼ŒéªŒè¯äº†å…¶è¯„ä¼°ç®¡é“çš„é«˜ä¿çœŸæ€§ã€‚  \nğŸ”¸Fast-dLLMåœ¨dLLMä¸­å®ç°åï¼Œæ¨ç†é€Ÿåº¦æå‡æœ€é«˜è¾¾11Ã—ï¼Œä¸”ç²¾åº¦åŸºæœ¬æ— æŸï¼Œè¯å®æ¡†æ¶å¯¹é«˜æ•ˆç®—æ³•çš„è‰¯å¥½æ”¯æŒã€‚  \nğŸ”¸MDLMå¾®è°ƒå¯æ˜¾è‘—æå‡å¤§DLMçš„æ¨ç†èƒ½åŠ›ï¼ˆå¦‚LLaDA-Instructåœ¨GSM8Kä¸Š+0.68%ï¼‰ï¼Œä½†Baseæ¨¡å‹åœ¨OODä»»åŠ¡ä¸Šå­˜åœ¨é€€åŒ–ç°è±¡ï¼Œæç¤ºSFTéœ€ä»»åŠ¡é€‚é…ã€‚  \nğŸ”¸BERT-Chatåœ¨é›¶æ¶æ„æ”¹åŠ¨ä¸‹è¶…è¶ŠGPT-2ç³»åˆ—ï¼Œè¯æ˜ç¼–ç å™¨ç»“æ„å…·å¤‡ç”Ÿæˆæ½œåŠ›ï¼›Tiny-A2Dä¸­BD3LMå˜ä½“åœ¨HumanEvalä¸Šåè¶…åŸARåŸºçº¿ï¼ŒéªŒè¯å—æ‰©æ•£å¯¹ä»£ç ç”Ÿæˆçš„ä¼˜åŠ¿ã€‚  \nğŸ”¸æ‰€æœ‰å°DLMå‡ä»…éœ€å•é˜¶æ®µSFTå®Œæˆè½¬æ¢ï¼Œè®­ç»ƒæˆæœ¬ä½ï¼ˆå¦‚BERT-Chatç”¨8Ã—A100è®­ç»ƒ10è½®ï¼‰ï¼Œå¤§å¹…é™ä½DLMå…¥é—¨é—¨æ§›ã€‚\n\nğŸ’¡ä¸ªäººè§‚ç‚¹  \nè¯¥å·¥ä½œæ ¸å¿ƒåˆ›æ–°åœ¨äºç³»ç»Ÿæ€§å·¥ç¨‹æŠ½è±¡ï¼šä¸æ˜¯æå‡ºæ–°æ¨¡å‹ï¼Œè€Œæ˜¯è¯†åˆ«å‡ºDLMç ”ç©¶ä¸­é‡å¤é€ è½®çš„å…±æ€§ç—›ç‚¹ï¼ˆè®­ç»ƒç›®æ ‡ç¢ç‰‡åŒ–ã€æ¨ç†APIä¸ä¸€è‡´ã€è¯„æµ‹ä¸å¯æ§ï¼‰ï¼Œå¹¶ä»¥å·¥ä¸šçº§è½¯ä»¶å·¥ç¨‹æ€ç»´æ„å»ºæ ‡å‡†åŒ–æ¥å£ã€‚å…¶â€œæœ€å°å¯è¡Œè½¬æ¢â€ç†å¿µï¼ˆå¦‚ARâ†’DLMä»…éœ€å‡ è¡Œé…ç½®å˜æ›´ï¼‰æå…·å®è·µä»·å€¼ï¼ŒçœŸæ­£æ¨åŠ¨DLMä»å®éªŒå®¤åŸå‹èµ°å‘å¯å¤ç°ã€å¯è¿­ä»£ã€å¯å…±äº«çš„å¼€æ”¾ç§‘ç ”èŒƒå¼ã€‚\n    "
    }
]