
🛎️北京大学
🔸2602.22681v1：提出LITE方法，首次建立统一黎曼ODE框架揭示预条件器与动量的协同机制，并据此设计面向扁平方向的动态增强策略，显著加速Muon和SOAP等先进优化器。
🔸2602.22859v1：提出诊断驱动的渐进式进化（DPE）框架，通过可解释的失败归因、动态数据混合调控与多智能体协同生成，实现针对能力盲点的闭环式迭代强化训练。
🔸2602.23111v1：提出PRAC方法，首次将激活的谱结构（主成分+长尾）显式建模，理论证明其在退化条件下可实现无偏且最小方差的梯度估计，达成最高36%总内存缩减。
🔸2602.22765v1：提出“二阶展开”概念与生成-批判联合训练框架GC-RL，显著提升同一训练数据下的生成与批判双能力。
🔸2602.22592v1：提出pQuant方法，通过解耦线性层为1比特主干与高精度敏感分支，并引入特征缩放机制动态引导敏感参数分配，显著提升极低比特模型的准确率与可扩展性。

🛎️哈尔滨工业大学
🔸2602.23258v1：提出AgentDropoutV2框架，首次实现测试时“先迭代纠正、再不可修复则裁剪”的动态信息流优化机制，显著提升MAS鲁棒性与准确性。

🛎️香港科技大学
🔸2602.23166v1：提出了AGENTVISTA——首个聚焦真实场景、细粒度视觉依赖、跨模态长程工具协同的多模态通用智能体评测基准。

🛎️清华大学
🔸2602.22623v1：提出ContextRL框架，通过上下文增强奖励模型与策略模型，显著提升MLLM在RL训练中的知识发现效率，缓解奖励作弊并提高小模型性能。
🔸2602.22703v1：提出GEOPERCEIVE基准与GEODPO框架，首次实现几何感知的解耦式评测与 translator-guided 强化学习优化，显著提升VLM在域内、域外及下游推理任务中的几何理解鲁棒性。
🔸2602.22808v1：提出MiroFlow——首个融合代理图编排、可选深度推理模式与鲁棒工作流机制的高性能开源智能体框架，在多个权威基准上实现可复现的SOTA性能。
🔸2602.23235v1：提出无需训练的GUIPruner框架，通过时序自适应分辨率调整与分层结构感知剪枝，兼顾效率提升与空间拓扑完整性，实现高保真、低开销的GUI导航。

🛎️香港中文大学
🔸2602.22581v1：提出IBCircuit框架，首次将信息瓶颈原理系统应用于电路发现，实现端到端、任务无关、整体优化的电路识别。

🛎️中国人民大学
🔸2602.22932v1：提出MSJoE框架，首次通过强化学习联合优化多模态大语言模型（MLLM）和轻量级关键帧采样器，实现推理引导的帧选择与感知-语言能力共适应。
🔸2602.22897v1：提出首个面向原生全模态智能体的基准OmniGAIA及配套智能体OmniAtlas，系统解决跨模态深度推理与主动感知下的工具协同难题。

🛎️上海交通大学
🔸2602.23061v1：提出MoDora系统，通过组件聚合、组件关联树（CCTree）建模与问题类型感知检索，显著提升跨元素、跨页、跨模态问答准确率。
🔸2602.22538v1：提出RAIN-Merging——一种无需梯度、分两阶段的模型融合方法，首次实现指令遵循能力与显式思维格式的协同保留与增强。
🔸2602.22868v1：提出ReMix框架，通过引入连续混合状态与拒绝机制，在无需重新训练的情况下，将DLLM推理速度提升2–8倍且不降低甚至提升输出质量。

🛎️浙江大学
🔸2602.22721v1：提出了Operation-R1框架，首次利用带可验证奖励的强化学习（RLVR）训练轻量级LLM（如Qwen-1.7B/4B），实现面向TQA的高质量数据准备管道的单步生成。

🛎️上海人工智能实验室
🔸2602.22556v1：提出首个兼顾训练稳定性与难度感知能力的两阶段自适应推理框架，通过优势塑形与长度感知梯度调控解决精度-效率权衡失稳和推理链长异质性导致的优化崩溃问题。
